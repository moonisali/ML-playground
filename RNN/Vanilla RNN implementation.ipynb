{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of vanilla RNN for character-level language model. This implementation is inspired by the great [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and lectures of Andrej Karpathy. For more details about RNNs please see references. Below you can see the math of forward pass and backward pass of simple network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are RNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Recurrent neural networks (RNNs)](https://en.wikipedia.org/wiki/Recurrent_neural_network) are a type of artificial neural network designed to recognize patterns in sequences of data, such as text, genomes, handwriting, the spoken word, or numerical times series data emanating from sensors, stock markets and government agencies. These algorithms take time and sequence into account, they have a temporal dimension. \n",
    "\n",
    "\n",
    "The necessity of RNNs is raising, when our current output depends on not only from current input, but some earlier inputs also. For example if we want to predict the next character of the word, then it basically depends on all the previous characters of word, or if want to predict gold price at timestamp $t_{n}$, then typically we have to take into consideration prices at earlier k timestamps $t_{n-k}, t_{n-k+1}, ... t_{n-1}$, where k can be even greater than 100. Traditional [feedforward neural networks](https://en.wikipedia.org/wiki/Feedforward_neural_network) do not handle such cases, because they do not have so called `internal memory`. For example if we are classifiying images using feedforward neural network then this network does not care which animal picture (cat or dog) is the first input: the outputs will not be changed if we reverse the order of inputs. That is, a feedforward network has no notion of order in time, and the only input it considers is the current example it has been exposed to. Feedforward networks are amnesiacs regarding their recent past; they remember nostalgically only the formative moments of training.\n",
    "\n",
    "\n",
    "Recurrent networks, on the other hand, take as their input not just the current input example they see, but also what they have perceived previously in time: they look quite similar to a traditional neural network except that a `memory-state` is added to the neurons.  Because of their internal memory, RNN’s are able to remember important things about the input they received, which enables them to be very precise in predicting what’s coming next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "print('RNN architecture')\n",
    "Image('data/01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above picture illustrates RNN basic architecture. \n",
    "\n",
    "The decision a recurrent net reached at time step `t-1` affects the decision it will reach one moment later at time step `t`. So recurrent networks have two sources of input, the present and the recent past, which combine to determine how they respond to new data, much as we do in life. This feedback loop connected to their past decisions, ingesting their own outputs moment after moment as input, is sp called `internal memmory`. It keeps the information from sequence itself. That sequential information is preserved in the recurrent network’s hidden state $h_{t}$, which manages to span many time steps as it cascades forward to affect the processing of each new example. It is finding correlations between events separated by many moments, and these correlations are called “long-term dependencies”, because an event downstream in time depends upon, and is a function of, one or more events that came before. So current output $y_{t}$ depends not only from current input $x_{t}$, but also from state at current moment $h_{t}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ h_{t} = f(W_{hh}h_{t-1} + W_{xh}x_{t}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{t} = W_{hy}h_{t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $h_{t}$ is the state at time $t$, $x_{t}$ an exogenous input at time $t$. The final output of the network $y_{t}$ at a certain timestamp $t$ is typically computed from one or more states $h_{t-k}, h_{t-k+1} \\cdots h_{t}$.\n",
    "\n",
    "\n",
    "$W_{hh}$, $W_{xh}$ and $W_{hy}$  are parameters like the weights parameters in feedforward nets.\n",
    "\n",
    "$f$ function is called activation function like for feedforward nets and can be $tanh, sigmoid, ReLU, \\cdots$ . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a RNN is similar to training a traditional Neural Network. We also use the backpropagation algorithm, but here algorithm is more complicated. The complex part is connected with parameters sharing across all time sequence: note that $W_{hh}$, $W_{xh}$ and $W_{hy}$ are the same for all $t$ and $t-1$. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. The algorithm for doing this is called [Backpropagation Through Time (BPTT)](https://en.wikipedia.org/wiki/Backpropagation_through_time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically we have to perform gradient descent, aka we have to change our model parameters $W_{hh}, W_{xh}, W_{hy}$ in a way, that loss is decreasing. So we have to calculate the following gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J}{\\partial W_{hy}}, \\frac{\\partial J}{\\partial W_{hh}}, \\frac{\\partial J}{\\partial W_{hx}} .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total loss for a given sequence of input values $ \\{x_{1}, x_{2}, \\cdots, x_{T}\\} $ paired with a sequence of target values $ \\{ target_{1}, target_{2}, \\cdots, target_{T} \\} $ would then be just\n",
    "the sum of the losses over all the time steps.\n",
    "\n",
    "$$ J = \\sum_{t=1}^{T} {J_{t}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just need to calculate $ \\frac{ \\partial J_{t}}{\\partial \\theta} $ and sum for all time steps, where $ \\theta $ is on of the followings $W_{hh}, W_{xh}, W_{hy}$, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{ \\partial J}{\\partial \\theta} = \n",
    "\\sum_{t=1}^{T}\n",
    "{\\frac{\\partial J_{t}}{\\partial \\theta}}\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Caluclating $ \\frac{ \\partial J_{t}}{\\partial W_{hy}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change $ W_{hy} $ it will affect only on $ y_{t} $, so using chain rule we will have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{ \\partial J_{t}}{\\partial W_{hy}} = \n",
    "\\frac{ \\partial J_{t}}{\\partial y_{t}} \\frac{ \\partial y_{t}}{\\partial W_{hy}}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Caluclating $ \\frac{ \\partial J_{t}}{\\partial W_{hh}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change $ W_{hh} $ it will affect on $ h_{t} $. But please note that $ h_{t} $ is complex function from $ W_{hh} $, because $ h_{t-1} $ is also depends on $ W_{hh} $. If we continue investigation we can see that $ h_{t-1} $ itself is a complex function from $ W_{hh} $ , as we have $ h_{t-1} = f(W_{hh}h_{t-2} + W_{xh}x_{t-1}) $. With the same logic we see that if we change $ W_{hh} $, it will affect all $ h_{k} $ for all $k$ from $1$ to $t$. \n",
    "\n",
    "So using chain rule will have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J_{t}}{\\partial W_{hh}} =  \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{k}}\n",
    "\\frac{\\partial^{+} h_{k}}{\\partial W_{hh}}} = \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial h_{k}} \n",
    "\\frac{\\partial^{+}  h_{k}}{\\partial W_{hh}}}\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for $t=3$ we will have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J_{3}}{\\partial W_{hh}} =  \n",
    "\\sum_{k=1}^{3}\n",
    "{\\frac{\\partial J_{3}}{\\partial h_{3}} \\frac{\\partial h_{3}}{\\partial h_{k}} \n",
    "\\frac{\\partial^{+}  h_{k}}{\\partial W_{hh}}} = \n",
    "\\frac{\\partial J_{3}}{\\partial h_{3}} \\frac{\\partial^{+}  h_{3}}{\\partial W_{hh}} \n",
    "+ \n",
    "\\frac{\\partial J_{3}}{\\partial h_{3}}  \\frac{\\partial h_{3}}{\\partial h_{2}}\n",
    "\\frac{\\partial^{+}  h_{2}}{\\partial W_{hh}}\n",
    "+\n",
    "\\frac{\\partial J_{3}}{\\partial h_{3}}  \\frac{\\partial h_{3}}{\\partial h_{2}} \\frac{\\partial h_{2}}{\\partial h_{1}} \\frac{\\partial^{+}  h_{1}}{\\partial W_{hh}}\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Caluclating $ \\frac{ \\partial J_{t}}{\\partial W_{xh}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the very simmilar logic as for $ W_{hh} $ will have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J_{t}}{\\partial W_{xh}} =  \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{k}}\n",
    "\\frac{\\partial^{+}  h_{k}}{\\partial W_{xh}}} = \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial h_{k}} \n",
    "\\frac{\\partial^{+} h_{k}}{\\partial W_{xh}}}\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for $t=3$ we will have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J_{3}}{\\partial W_{xh}} =  \n",
    "\\sum_{k=1}^{}\n",
    "{\\frac{\\partial J_{3}}{\\partial h_{3}} \\frac{\\partial h_{3}}{\\partial h_{k}} \n",
    "\\frac{\\partial^{+}  h_{k}}{\\partial W_{xh}}} = \n",
    "\\frac{\\partial J_{3}}{\\partial h_{3}} \\frac{\\partial^{+}  h_{3}}{\\partial W_{xh}} \n",
    "+ \n",
    "\\frac{\\partial J_{3}}{\\partial h_{3}}  \\frac{\\partial h_{3}}{\\partial h_{2}} \n",
    "\\frac{\\partial^{+}  h_{2}}{\\partial W_{hh}}\n",
    "+\n",
    "\\frac{\\partial J_{3}}{\\partial h_{3}}  \\frac{\\partial h_{3}}{\\partial h_{2}} \\frac{\\partial h_{2}}{\\partial h_{1}} \\frac{\\partial^{+}  h_{1}}{\\partial W_{xh}}\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note that in above formulas $ \\frac{\\partial^{+}  h_{k}}{\\partial \\theta} $ refers to the\n",
    "“immediate” partial derivative of the state $ h_{k} $ with respect to $\\theta$, where $h_{k-1}$ is taken as a constant with respect to $\\theta$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-Level Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train RNN character-level language models. That is, we will give the RNN a huge chunk of text and ask it to model the probability distribution of the next character in the sequence given a sequence of previous characters. This will then allow us to generate new text one character at a time.\n",
    "\n",
    "Imagine we have a small vocabulary of four possible letters “helo”, and wanted to train an RNN on the training sequence “hello”. This training sequence is in fact a source of 4 separate training examples:\n",
    "\n",
    "1. The probability of “e” should be likely given the context of “h”\n",
    "2. “l” should be likely in the context of “he”\n",
    "3. “l” should also be likely given the context of “hel”\n",
    "4. “o” should be likely given the context of “hell”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concretely, we will do one-hot-encoding for each character in our dataset and feed them into the RNN one at a time. We will then observe a sequence of 4-dimensional output vectors (one dimension per character), which we interpret as the confidence the RNN currently assigns to each character coming next in the sequence. Here’s a diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('data/charseq.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we the following steps have been illustrated: \n",
    "\n",
    "1. Updading the hidden state using new input: $ h_{t} = \\tanh(W_{hh}h_{t-1} + W_{xh}x_{t}) $\n",
    "2. Getting output using hidden state: $ y_{t} = W_{hy}h_{t} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to take into consideration also the a desired target character at every one of the 4 time steps. We would like that our network assigns a maximum confidence to that desired character. In order to do it we pass the output through softmax layer to normalize the output that allows us to express it as a probability. \n",
    "\n",
    "3. Passing through Softmax: $ p_{t} = softmax(y_{t}) $\n",
    "\n",
    "The $p_{t}$ will represent the probability distribution for the next character: $p_{t}[i]$ is the probability of index $i$ being the next character at time step $t$. \n",
    "\n",
    "The objective of our model is to make the green numbers as big as we can and the red numbers as small as we can in the probability distribution layer. The reason is that the true index should have the highest probability by making it as close as we can to 1. The way to do that is to measure the loss using cross-entropy and then compute the gradients of the loss w.r.t. all parameters to update them in the opposite of the gradient direction. \n",
    "\n",
    "4. Cross Entropy loss: $ J_{t}(label_{t}, {p}_t) = - label_{t} \\log p_{t} \\\\ J(labels, ps) = \\sum_{t=1}^{T} {J_{t}} $\n",
    "\n",
    "Here, $ label_{t}$ is the correct character at time step $t$, and $p_{t}$ is our prediction. \n",
    "\n",
    "Afterwards we should update parameters them in the opposite of the gradient direction. So we should calculate the loss gradient w.r.t. all parameters:  $W_{hh}, W_{xh}, W_{hy}$:\n",
    "\n",
    "5. Calculating loss gradients w.r.t. model parameters:\n",
    "$ \\frac{\\partial J}{\\partial W_{hy}}, \\frac{\\partial J}{\\partial W_{hh}}, \\frac{\\partial J}{\\partial W_{hx}} $\n",
    "\n",
    "Afterwards we should make gradient descent step.\n",
    "6. Updating parameters in the opposite of the gradient direction: \n",
    "$\\theta \\leftarrow \\theta - \\alpha \\cdot \\frac{\\partial J}{\\partial \\theta}$\n",
    "\n",
    "Repeating the process over many times where each time we adjust the parameters based on the gradient direction $\\rightarrow $ model will be able to correctly predict next characters given all previous ones using all names in the training text. Notice that hidden state $h$ has all past information about all characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import softmax, sigmoid, tanh, relu, dsigmoid, drelu, dtanh, one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ W_{hh} $ - hidden to hidden weight matrix, size = (hidden_size, hidden_size)\n",
    "* $ W_{hx} $ - input to hidden weight matrix, size = (hidden_size, vocabulary_size)\n",
    "* $ W_{hy} $ - hidden to output weight matrix, size = (vocabulary_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Hyper - Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hidden_size - the size of hidden state\n",
    "* sequence length - the number of previous characters which affect on the next character\n",
    "* learning rate - the small number for performing SGD\n",
    "* activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize our model with random weight matrices and with hidden state $h_{0} = [0, 0, 0, ...,0]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \"\"\"\n",
    "    This class represents simple Recurrent Neural Network implementation for\n",
    "    character-level language model. The purpose of the network is correctly predicting the next\n",
    "    character, given the previous sequence of characters.\n",
    "    \"\"\"\n",
    "\n",
    "    activations = {\n",
    "        'tanh': (tanh, dtanh),\n",
    "        'sigmoid': (sigmoid, dsigmoid),\n",
    "        'relu': (relu, drelu)\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocabulary_size: int,\n",
    "                 hidden_size: int,\n",
    "                 non_linearity: str = 'tanh'):\n",
    "        \"\"\"\n",
    "        :param vocabulary_size: the size of vocabulary, aka the number of unique characters in\n",
    "                                vocabulary\n",
    "        :param hidden_size: the size of hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        if non_linearity not in self.activations:\n",
    "            raise ValueError(f'Non linearity must be one of the followings: '\n",
    "                             f'{tuple(self.activations)}.')\n",
    "\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # activation function and its dervivate w.r.t. its direct input\n",
    "        self.f, self.f_prime = self.activations[non_linearity]\n",
    "\n",
    "        # randomly initializing weights\n",
    "\n",
    "        self.w_hx = np.random.uniform(\n",
    "            -np.sqrt(1. / vocabulary_size), np.sqrt(1. / vocabulary_size),\n",
    "            (hidden_size, vocabulary_size)\n",
    "        )\n",
    "\n",
    "        self.w_hh = np.random.uniform(\n",
    "            -np.sqrt(1. / hidden_size), np.sqrt(1. / hidden_size),\n",
    "            (hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "        self.w_hy = np.random.uniform(\n",
    "            -np.sqrt(1. / hidden_size), np.sqrt(1. / hidden_size),\n",
    "            (vocabulary_size, hidden_size)\n",
    "        )\n",
    "\n",
    "        # setting the current state\n",
    "        self.current_state = np.zeros((self.hidden_size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the implementation for forward passing. $x$ is the sequence array, where each item is the index of characters. Index is taken from our vocabulary. We make one-hot encoding of this input array and for each item in sequence make forward pass.\n",
    "\n",
    "$ \\text{for each } x_{t} \\text{ in input_x}$:\n",
    "   1. $ z_{t} = W_{hh}h_{t-1} + W_{xh}x_{t} $\n",
    "   2. $ h_{t} = f(z_{t}) $\n",
    "   3. $ y_{t} = W_{hy}h_{t} $\n",
    "   4. $ p_{t} = softmax(y_{t}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x: np.ndarray, update_state: bool) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    The basic forward pass:\n",
    "\n",
    "    z_{t} = w_hh * h_{t-1} + w_hx * x_{t}\n",
    "    h_{t} = f(z_{t})\n",
    "    y_{t} = w_hy * h_{t}\n",
    "    p_{t} = softmax(y_{t})\n",
    "\n",
    "    Makes forward pass through network.\n",
    "    :param x: the array of integers, where each item is the index of character, the size of\n",
    "              array will be the sequence length\n",
    "    :param update_state: bool, if True updates current state with last state\n",
    "    :return: the tuple of states and predicted_probabilities\n",
    "             states - array of states, size = (sequence length, hidden size)\n",
    "             predicted_probabilities - array of predicted probabilities for each character in\n",
    "                                       vocabulary, size = (sequence length, vocabulary size)\n",
    "    \"\"\"\n",
    "    # one hot encoding of input\n",
    "    inputs_matrix = one_hot_encode(x, self.vocabulary_size)\n",
    "\n",
    "    ps, hs = {}, {}  # predicted probabilities and hidden states\n",
    "    hs[-1] = self.current_state  # setting the current state\n",
    "    for t in range(len(x)):\n",
    "        # state at t - 1\n",
    "        h_t_1 = hs[t - 1]  # dim : (self.hidden_size, 1)\n",
    "\n",
    "        # state at t\n",
    "        z_t = np.dot(self.w_hh, h_t_1) + np.dot(self.w_hx, inputs_matrix[t])\n",
    "        h_t = self.f(z_t)  # dim : (self.hidden_size, 1)\n",
    "\n",
    "        # prediction from hidden state at t\n",
    "        y_t = np.dot(self.w_hy, h_t)  # unnormalized log probabilities for next chars\n",
    "        p_t = softmax(y_t)  # probabilities for next chars,  dim : (self.vocabulary_size, 1)\n",
    "\n",
    "        # updating hidden state and and predicted_probabilities keepers\n",
    "        hs[t], ps[t] = h_t, p_t\n",
    "\n",
    "    if update_state:\n",
    "        self.current_state = hs[len(x) - 1]  # updating the current state\n",
    "    return hs, ps\n",
    "\n",
    "RNN.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{for each } x_{t} \\text{ in input_x}$:\n",
    "   1. calculate the $p_{t}$ using forward pass, where $p_{t}$ is the array with size = vocabulary_size and $p_{t}[i]$ is the probability that next character will be a character from vocabulary with index $i$\n",
    "   2. calculate $ J_{t} = - label_{t} \\log(p_{t}) $, where $label_{t}$ is the one hot encoded array with 0s and 1, the 1 index is the correct character index in the vocabulary\n",
    "  \n",
    "Sum all $ J_{t} $ : $ J = \\sum_{t = 1}^{T} {J_{t}} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(self, x: np.ndarray, labels: np.ndarray, update_state: bool) -> float:\n",
    "    \"\"\"\n",
    "    Calculates cross entropy loss using target characters indexes and network predictions for\n",
    "    all characters: loss = ∑ -label_{t} * log(predicted_probability_{t})\n",
    "    \"\"\"\n",
    "    _, ps = self.forward(x, update_state)\n",
    "    return -sum(np.log(ps[i][labels[i], 0]) for i in range(len(labels)))\n",
    "\n",
    "RNN.calculate_loss = calculate_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Backpropogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the most tricky part. We have to calculate loss gradient w.r.t. to model all parameters $ W_{xh}, W_{hh}, W_{hy}$. We will use the formulas defined in [RNN Training](#RNN-Training) part. We even fill go further and consider $h_{t}$  as a function of $z_{t}$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{ \\partial J_{t}}{\\partial W_{hy}} = \n",
    "\\frac{ \\partial J_{t}}{\\partial y_{t}} \\frac{ \\partial y_{t}}{\\partial W_{hy}}. \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J_{t}}{\\partial W_{hh}} =  \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{k}}\n",
    "\\frac{\\partial^{+} h_{k}}{\\partial W_{hh}}} = \n",
    "\\sum_{k=1}^{t}\n",
    "{\n",
    "\\frac{\\partial J_{t}}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial h_{k}} \n",
    "\\frac{\\partial^{+}  h_{k}}{\\partial W_{hh}}\n",
    "}=\n",
    "\\sum_{k=1}^{t}\n",
    "{\n",
    "\\frac{\\partial J_{t}}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial z_{t}} \n",
    "\\frac{\\partial z_{t}}{\\partial h_{k}} \\frac{\\partial h_{k}}{\\partial z_{k}} \n",
    "\\frac{\\partial^{+}  z_{k}}{\\partial W_{hh}}\n",
    "}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J_{t}}{\\partial W_{xh}} =  \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{k}}\n",
    "\\frac{\\partial^{+}  h_{k}}{\\partial W_{xh}}} = \n",
    "\\sum_{k=1}^{t}\n",
    "{\\frac{\\partial J_{t}}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial h_{k}} \n",
    "\\frac{\\partial^{+} h_{k}}{\\partial W_{xh}}}=\n",
    "\\sum_{k=1}^{t}\n",
    "{\n",
    "\\frac{\\partial J_{t}}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial z_{t}} \n",
    "\\frac{\\partial z_{t}}{\\partial h_{k}} \\frac{\\partial h_{k}}{\\partial z_{k}} \n",
    "\\frac{\\partial^{+}  z_{k}}{\\partial W_{xh}}\n",
    "}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{ \\partial J}{\\partial \\theta} = \n",
    "\\sum_{t=1}^{T}\n",
    "{\\frac{\\partial J_{t}}{\\partial \\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acording to this formulas we have to calculate also the follwoing gradients: \n",
    "$\n",
    "\\frac{ \\partial J_{t}}{\\partial y_{t}},\n",
    "\\frac{\\partial J_{t}}{\\partial h_{t}},\n",
    "\\frac{\\partial h_{t}}{\\partial z_{t}}, \n",
    "\\frac{\\partial z_{t}}{\\partial h_{t-1}}, \n",
    "\\frac{\\partial^{+}  z_{t}}{\\partial W_{hh}}, \n",
    "\\frac{\\partial^{+}  z_{t}}{\\partial W_{xh}},\n",
    "\\frac{ \\partial y_{t}}{\\partial W_{hy}}\n",
    "$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Differentiating softmax function, we get \n",
    "\n",
    "$$ \\frac{\\partial J_{t}}{\\partial y_{t}} = p_{t} - labels_{t} .$$\n",
    "\n",
    "2. Differentiating $y_{t} = W_{hy} h_{t}$, we get\n",
    "\n",
    "$$ \\frac{\\partial J_{t}}{\\partial W_{hy}} = \\frac{ \\partial J_{t}}{\\partial y_{t}} \\frac{ \\partial y_{t}}{\\partial W_{hy}} = (p_{t} - labels_{t})h_{t} $$\n",
    "\n",
    "$$ \\frac{\\partial J_{t}}{\\partial h_{t}} = \\frac{ \\partial J_{t}}{\\partial y_{t}} \\frac{ \\partial y_{t}}{\\partial h_{t}} = (p_{t} - labels_{t})W_{hy} .$$\n",
    "\n",
    "3. Differentiating $h_{t} = f(z_{t})$, we get\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial h_{t}}{\\partial z_{t}} = \n",
    "\\frac{\\partial f}{\\partial z_{t}} =\n",
    "\\begin{cases} \n",
    "    1 - \\tanh^2{z_{t}}, & \\text{ if } f = \\tanh \\\\\n",
    "    \\sigma(z_{t})(1 - \\sigma(z_{t})), & \\text{ if } f = \\sigma\n",
    "\\end{cases} =\n",
    "\\begin{cases} \n",
    "    1 - h_{t} ^ 2, & \\text{ if } f = \\tanh \\\\\n",
    "    h_{t}(1 - h_{t}), & \\text{ if } f = \\sigma\n",
    "\\end{cases} $$\n",
    "\n",
    "4. Differentiating $ z_{t} = W_{hh}h_{t-1} + W_{xh}x_{t} $, we get\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial z_{t}}{\\partial h_{t - 1}} = W_{hh},\n",
    "\\text{   } \n",
    "\\frac{\\partial z_{t}}{\\partial W_{xh}} = x_{t},\n",
    "\\text{   }\n",
    "\\frac{\\partial z_{t}}{\\partial W_{hh}} = h_{t - 1}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all these formulas we have mplemented the backward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, x: np.ndarray, labels: np.ndarray, hs: Dict, ps: Dict):\n",
    "    \"\"\"\n",
    "    Makes backward pass through the network. Returns the gradients of loss w.r.t. network\n",
    "    parameters -  w_hx, w_hh, w_hy.\n",
    "\n",
    "    :param x: the array of input characters, where each item is the index of character, the\n",
    "              size of array will be the sequence length\n",
    "    :param labels: the array of target characters, where each item is the index of character,\n",
    "                   the size of array will be the sequence length\n",
    "    :param hs: the hidden states of network, (the first output of the self.forward method)\n",
    "    :param ps: network predictions for given inputs,\n",
    "               (the second output of the self.forward method)\n",
    "    :return: gradients of w_hx, w_hh, w_hy\n",
    "    \"\"\"\n",
    "    inputs_matrix = one_hot_encode(x, self.vocabulary_size)\n",
    "    labels_matrix = one_hot_encode(labels, self.vocabulary_size)\n",
    "\n",
    "    dw_hx = np.zeros_like(self.w_hx)\n",
    "    dw_hh = np.zeros_like(self.w_hh)\n",
    "    dw_hy = np.zeros_like(self.w_hy)\n",
    "\n",
    "    for t in reversed(range(len(x))):\n",
    "        # dl / dy = p - label\n",
    "        dy_t = ps[t] - labels_matrix[t]\n",
    "       \n",
    "        # dl / dw_hy = (dl / dy) * (dy / dw_hy)\n",
    "        dw_hy += np.dot(dy_t, hs[t].T)\n",
    "        \n",
    "        # dl / dh = (dl / dy) * (dy / dh) = (p - label) * w_hy\n",
    "        dh_t = np.dot(self.w_hy.T, dy_t)\n",
    "\n",
    "        # dl / dz_{k} = (dl / dh_{k}) * (dh_{k} / dz_{k}) = dh_{t} * (dh_{k} / dz_{k}), when t = k\n",
    "        dz_k = dh_t * self.f_prime(hs[t])\n",
    "\n",
    "        # dl / dw_hh = ∑ (dl / dz_{k}) * (dz_{k} / dw_hh) for all k from 1 to t\n",
    "        # dl / dw_hx = ∑ (dl / dz_{k}) * (dz_{k} / dw_hx) for all k from 1 to t\n",
    "        for k in reversed(range(t + 1)):\n",
    "            # (dl / dz_{k}) (dz_{k} / dw_hh) = dz_k * h_{k-1}\n",
    "            dw_hh += np.dot(dz_k, hs[k - 1].T)\n",
    "\n",
    "            # (dl / dz_{k}) (dz_{k} / dw_h) = dz_k * x_{k}\n",
    "            dw_hx += np.dot(dz_k, inputs_matrix[k].T)\n",
    "\n",
    "            # updating dz_k using all previous derivatives (from t to t - k)\n",
    "            # dl / dz_(k-1) = (dl / dz_{k})(dz_{k} / dh_{k-1}) * (dh_{k-1) / dz_{k-1})\n",
    "            dz_k = np.dot(self.w_hh.T, dz_k) * self.f_prime(hs[k - 1])\n",
    "\n",
    "    # clip to mitigate exploding gradients\n",
    "    for d_param in (dw_hx, dw_hh, dw_hy):\n",
    "        np.clip(d_param, -5, 5, out=d_param)\n",
    "\n",
    "    return dw_hx, dw_hh, dw_hy\n",
    "\n",
    "RNN.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is updating parameters:\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\alpha \\cdot \\frac{\\partial J}{\\partial \\theta}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_step(self, x: np.ndarray, labels: np.ndarray, lr: float):\n",
    "    \"\"\"\n",
    "    Performs gradient descent step for model parameters: w_hx, w_hh, w_hy.\n",
    "\n",
    "    - forward pass: calculating next char probabilities, given previous sequence of chars\n",
    "    - backward pass: calculating loss and its gradient w.r.t. model params\n",
    "    - sgd update: update params in the opposite of the gradient direction\n",
    "    \"\"\"\n",
    "    hs, ps = self.forward(x, True)\n",
    "    dw_hx, dw_hh, dw_hy = self.backward(x, labels, hs, ps)\n",
    "\n",
    "    # w <-- w - lr * dloss / dw\n",
    "    self.w_hx -= lr * dw_hx\n",
    "    self.w_hh -= lr * dw_hh\n",
    "    self.w_hy -= lr * dw_hy\n",
    "\n",
    "RNN.sgd_step = sgd_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details about RNNs:\n",
    "\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "* https://www.youtube.com/watch?v=iX5V1WpxxkY\n",
    "* https://towardsdatascience.com/recurrent-neural-networks-and-lstm-4b601dd822a5\n",
    "* https://skymind.ai/wiki/lstm#two\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://blog.echen.me/2017/05/30/exploring-lstms/\n",
    "\n",
    "\n",
    "For more details about Backpropagation Through Time (BPTT):\n",
    "\n",
    "* https://arxiv.org/pdf/1610.02583.pdf\n",
    "* http://willwolf.io/2016/10/18/recurrent-neural-network-gradients-and-lessons-learned-therein/\n",
    "* http://proceedings.mlr.press/v28/pascanu13.pdf\n",
    "* http://colah.github.io/posts/2015-08-Backprop/\n",
    "* https://fdsmlhn.github.io/2017/10/22/Derivation%20of%20Back%20Propagation%20Through%20Time%20(BPTT)%20-%20Vanilla%20Recurrent%20Neural%20Network(RNN)/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
